{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rSs52SOmtAO"
      },
      "source": [
        "Here im doing transfer learning and fine tunning with a resnet50 and pytorch, to classify bees and cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkliWcyTFL5c",
        "outputId": "13f68c8d-eb0c-4127-a24c-e384197bf867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title colab sincronization and dict of labels\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "label_dic = {0:'Bee',\n",
        "             1:'Cat'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acMukUmR8vul",
        "outputId": "56723bfd-7a5e-4801-9d2b-fb9f7ac79b77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['bee', 'cat']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, dataset\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "mean_data = torch.tensor([0.485, 0.456, 0.406])\n",
        "std_data = torch.tensor([0.229, 0.224, 0.225])\n",
        "# Define a transform to preprocess the input images\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_data, std_data) # Normalize the pixel values\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_data, std_data) # Normalize the pixel values\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Import Data\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/data_resnet'\n",
        "sets = ['train', 'validation']\n",
        "image_datasets = {x:datasets.ImageFolder(os.path.join(data_dir, x), \n",
        "                                         data_transforms[x])\n",
        "                  for x in ['train', 'validation']}\n",
        "\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size = 4,\n",
        "                             shuffle = True)\n",
        "               for x in ['train', 'validation']}\n",
        "\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}\n",
        "class_names = image_datasets['train'].classes\n",
        "print(class_names)\n",
        "\n",
        "# Training \n",
        "def train_model(model, criterion, optimazer, scheduler, num_epochs = 10):\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "        \n",
        "        #Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train() # set the model in training mode\n",
        "            else:\n",
        "                model.eval()  # set the model in evaluation mode\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "                \n",
        "                \n",
        "            # iterate over data\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                #forward\n",
        "                #track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    \n",
        "                #backward + optimize, only if is training phase\n",
        "                if phase == 'train':\n",
        "                    # Clean the gradients of the parameters to optimize. \n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step() # Updating the weights\n",
        "            \n",
        "            #statistics\n",
        "            running_loss +=loss.item()* inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "        if phase == 'train':\n",
        "            scheduler.step()\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double()/ dataset_sizes[phase]\n",
        "        \n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "        \n",
        "        #deep copy the model \n",
        "        if phase == 'validation' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    print()\n",
        "    \n",
        "    print(f'Training Complete, Best Val Acc: {best_acc:.4f}')\n",
        "    \n",
        "    # Load best model Weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsoLoUSg8vup",
        "outputId": "ec0e36c2-cab2-49de-c195-5598549ce18f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 1/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 2/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 3/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 4/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 5/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 6/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 7/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 8/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 9/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "Epoch 10/10\n",
            "----------\n",
            "validation Loss: 0.0000 Acc: 0.0667\n",
            "\n",
            "Training Complete, Best Val Acc: 0.0667\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(pretrained = True)\n",
        "\n",
        "# Now we will freeze the first layers of the NN, to train the weights only \n",
        "# of the latest layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# The resnet50 was trained on ImageNet dataset, that's why it has 1000 labels in \n",
        "# the output layer (out_features), in our implementation, we want to classify only \n",
        "# 2 labels(bees & ants, so, we will edit the last layer of the resnet.\n",
        "\n",
        "num_classes = 2\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "\n",
        "# model to GPU\n",
        "device = torch.device(\"cuda:0\") # to run on macOS \"mps\" instead of \"cuda:0\"\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# Define a loss function and an optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "# optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
        "# optimizer = torch.optim.Adadelta(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# Every 7 epochs our learning rate its only update 10%.\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma = 0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs= 11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "DwHqbzsRBL8A"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"./resnet50_finetuned.pth\") # saving the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "AlYMDqctLazA"
      },
      "outputs": [],
      "source": [
        "# model_loaded = models.resnet50(pretrained = True) # Loading the weights that i saved before\n",
        "\n",
        "# num_classes = 2\n",
        "# num_ftrs = model_loaded.fc.in_features\n",
        "# model_loaded.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# model_loaded.load_state_dict(torch.load(\"./resnet50_finetuned.pth\"))\n",
        "# model_loaded.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XS4figvt8vur",
        "outputId": "a2c99ab1-6677-49d1-b946-7218c59f8b11"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bee'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To resize and crop the image, you can use the Resize and CenterCrop transforms\n",
        "# To convert the image to a tensor and normalize its pixel values, you can use \n",
        "# the ToTensor and Normalize \n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_data, std_data)\n",
        "])\n",
        "\n",
        "\n",
        "X_test = Image.open('/content/drive/MyDrive/Colab Notebooks/finaltest_resnet.jpg')\n",
        "image_tensor = transform_test(X_test)\n",
        "image_tensor = image_tensor.unsqueeze(0)\n",
        "\n",
        "image_tensor = image_tensor.to(device)\n",
        "\n",
        "y_pred = model(image_tensor)\n",
        "_, pred = torch.max(y_pred, 1)\n",
        "label_dic[pred.item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "WyUdFftrXK6v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.8 ('redes')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "466813897a52447f1831c184b0700fb7b7f042a70becf90568dd3beaa877b3ca"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
